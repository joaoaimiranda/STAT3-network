











import pandas as pd
import omnipath as op
from gprofiler import GProfiler











transcriptnet = op.interactions.Transcriptional.get(
    #sources="STAT3", #---------------------> usar para obter apenas os alvos do STAT3
    databases="DoRothEA", #-----------------> Existem várias bases de dados com informação de interação transcricional
    dorothea_levels=["A", "B", "C", "D"], #-> Níveis de evidência que suportam a interações do DoRothEA
    genesymbols=True, #---------------------> Para além dos identificadores uniprot queremos também os gene symbols oficiais 
    organism="human" 
)
print(transcriptnet.shape)
transcriptnet.head()


# Filtrar as interações interactions para incluir apenas os alvos do STAT3
stat3targets = transcriptnet.loc[
    transcriptnet["source_genesymbol"]=="STAT3",
    ["source_genesymbol", "target_genesymbol", "is_stimulation", "is_inhibition"]
]\
.drop_duplicates().reset_index(drop=True).rename(columns={
    "source_genesymbol": "source",
    "target_genesymbol": "target"
})

# Adicionar a coluna effect que descreve o efeito da regulação dos gene pelo STAT3
stat3targets["effect"] =\
    stat3targets.pop("is_stimulation").astype(int) -\
    stat3targets.pop("is_inhibition").astype(int)

# Na ausência de anotação de efeito vamos assumir que o STAT3 promove a transcrição do gene
stat3targets.loc[stat3targets["effect"]==0, "effect"] = 1

# guardar a lista num ficheiro
stat3targets.to_csv("stat3_targets.txt", index=False, header=False)
print(len(stat3targets))
stat3targets.head()


# Adicionalmente vamos guardar uma lista de todos os genes alvo presentes no DoRothEA
dorotheatargets = transcriptnet["target_genesymbol"].drop_duplicates()\
.reset_index(drop=True).rename("dorotheatargets")

# guardar ficheiro
dorotheatargets.to_csv("dorothea_targets.txt", index=False, header=False)
print(len(dorotheatargets))
dorotheatargets.head()





goea = GProfiler(return_dataframe=True).profile(
    query=stat3targets["target"].tolist(), #--> a nossa lista de genes alvos do STAT3
    organism="hsapiens", #--------------------> organismo de interesse
    sources=["GO:BP"], #----------------------> "Biological Processes (BP)" ramo da Gene Ontology em que nos interessa pesquisar 
    user_threshold= 0.05, #-------------------> nível de significância (p-value < 0.05)
    all_results=True, #-----------------------> inclui os resultados que não são significativos 
    no_evidences=False, #---------------------> inclui as colunas da interseção e das evidências
    domain_scope="annotated", #---------------> usar apenas os genes do nosso universo que estão anotados em GO
    significance_threshold_method="g_SCS", #--> tipo de correção para testes múltiplos
    background=dorotheatargets.tolist() #-----> universo do teste estatístico (todos os alvos no DoRothEA)
)
goea.head()


# Vamos procurar os termos GO que contém NF-kappaB no nome e são estatisticamente significativos
# Podemos afirmar que esses termos são constituídos por genes relacionados com a via 
nfkbterms = goea[(goea["name"].str.contains("NF-kappaB"))&(goea["significant"])]
nfkbterms


# Os alvos do STAT3 estão enriquecidos em dois termos relacionados com a via canónica
# A coluna intersections contém todos os genes dos termos que nos interessam
term1, term2 = nfkbterms["intersections"]
term1, term2 = set(term1), set(term2)
print(len(term1), len(term2))


print(term1 >= term2) # testa se o conjunto term2 é um subconjunto de term1
print(term1 - term2) # devolve a diferença entre os dois conjuntos

stat3_nfkb_targets = list(term1 | term2) # calcula a união dos dois conjuntos

# transformar em DataFrame
stat3_nfkb_targets = pd.DataFrame(stat3_nfkb_targets, columns=["target"])

stat3_nfkb_targets





# ler o ficheiro com os genes do termo Canonical NF-kappaB signal transduction
nfkbgenes = pd.read_table("canonical_nfkb_pathway_term.txt", names=["gene"])["gene"]\
.drop_duplicates()
print(len(nfkbgenes))
display(nfkbgenes.head())

# transformar a Series em DataFrame
nfkbgenes = pd.DataFrame(nfkbgenes.rename("target"))
nfkbgenes["protein_type"] = ["pathway"]*len(nfkbgenes)
print(len(nfkbgenes))
nfkbgenes.head()





# lista da interseção da análise de enriquecimento
stat3_nfkb_targets.head()


transcriptmod = stat3_nfkb_targets.pipe(
    # merge que adiciona a coluna identificadora protein_type e mantém as chaves
    pd.merge, nfkbgenes, on="target", how="left"  
).fillna(
    # preenche os elementos em falta na coluna protein_type
    "regulator", axis=1
).pipe(
    # merge que adiciona a coluna source com a proteína STAT3
    pd.merge, stat3targets, on="target", how="inner")\
 

transcriptmod = transcriptmod[["source", "target", "effect", "protein_type"]]
print(len(transcriptmod))
transcriptmod





# descarregar a via da sinalização
signalnet = op.interactions.PostTranslational.get(
    directed=True,
    genesymbols=True,
    organism="human"
)
print(len(signalnet))
signalnet.head()


# verificar se existem complexos proteicos rede
signalnet.loc[
    signalnet["source_genesymbol"].str.contains(r'[:_]')|
    signalnet["target_genesymbol"].str.contains(r'[:_]'),
    ['source_genesymbol', 'target_genesymbol']
].head(5)


# selecionar colunas
signalnetfiltered = signalnet[
["source_genesymbol", "target_genesymbol", "is_stimulation", "is_inhibition"]]\
.rename(columns={"source_genesymbol": "source", "target_genesymbol": "target"})\
.drop_duplicates()

# separar as interações com complexos em interações com proteínas individuais
signalnetfiltered = signalnetfiltered.assign(
    source = signalnetfiltered["source"].str.split("_"),
    target = signalnetfiltered["target"].str.split("_")
)\
.explode("source").explode("target").drop_duplicates()

print(len(signalnetfiltered))
signalnetfiltered.head()


# Os genes "source" são as proteínas do módulo transcricional anotadas como reguladoras
source = transcriptmod.loc[transcriptmod["protein_type"]=="regulator", "target"].tolist()

# Os genes "target" pertencem à via do NF-kB
target = nfkbgenes["target"].tolist()

# Filtrar a rede de sinalização com as listas de genes
signalmod = signalnetfiltered[
    (signalnetfiltered["source"].isin(source))&
    (signalnetfiltered["target"].isin(target))
].copy()

# criar coluna de efeito
signalmod["effect"] = signalmod.pop("is_stimulation").astype(int) +\
                        signalmod.pop("is_inhibition").astype(int)
signalmod.loc[signalmod["effect"]==2, "effect"] = 0
print(len(signalmod))
signalmod.head()





# o primeiro ficheiro contém as interações da rede
network = pd.concat([
    transcriptmod.drop(columns="protein_type"), signalmod],
    ignore_index=True
)

network["interaction_type"] = ["transcriptional"]*len(transcriptmod) + ["signalling"]*len(signalmod)
network["directed"] = [True]*len(network)
network.to_csv("nfkb_network.csv", index=False)
network


# também criaremos um ficheiro com os nós (proteínas) da rede e os seus atributos
# começamos por selecionar os nós do módulo transcricional
nodes = pd.concat([
    transcriptmod[["target", "protein_type"]].rename(columns={"target": "protein"}),
    pd.DataFrame({"protein": "STAT3", "protein_type": "TF"}, index=[len(transcriptmod)])
])
print(len(nodes))
nodes.head()


# adicionar os nós do módulo de sinalização, que inclui proteínas da via
# e complexos ausentes do módulo transcricional

for proteinlist, proteintype in zip(["source", "target"], ["regulator", "pathway"]):
    # selecionar os genes de uma coluna (source ou target)
    proteins = signalmod[[proteinlist]]\
        .rename(columns={f"{proteinlist}": "protein"})
    # criar coluna
    proteins["protein_type"] = [proteintype]*len(proteins)
    
    # concatenar os novos nós
    nodes = pd.concat([nodes, proteins], ignore_index=True)

nodes.drop_duplicates(inplace=True)
nodes.to_csv("network_proteins.csv", index=False)
print(len(nodes))
nodes.tail()





modelprots = {
    "TNFa": ["TNF"],
    "IKKa": ["CHUK", "IKBKB", "IKBKG"],
    "IkBa": ["NFKBIA"],
    "NFkB": ["RELA", "REL", "NFKB1"],
    "A20": ["TNFAIP3", "TNIP1"]
}



